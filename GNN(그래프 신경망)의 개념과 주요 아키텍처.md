# GNN(그래프 신경망) 핵심 요약 🧠

---

## 1. GNN의 기본 원리

-   **핵심 아이디어**: GNN은 노드의 특징 정보와 그래프의 구조 정보를 모두 활용하여 노드를 표현하는 모델입니다.
-   **메시지 패싱**: 모든 GNN의 근간이 되는 원리로, 각 노드가 이웃 노드들의 정보를 **집계(Aggregate)**하고, 집계된 정보와 자신의 이전 정보를 바탕으로 상태를 **갱신(Update)**하는 과정을 반복합니다.
-   **입력 데이터**: GNN은 두 가지 핵심 정보를 입력으로 받습니다.
    1.  **인접 행렬 (A)**: 노드 간의 연결 관계 (그래프 구조)
    2.  **노드 특징 행렬 (X)**: 각 노드가 가진 고유한 속성

---

## 2. 주요 GNN 아키텍처 비교

| 모델                | **GCN (Graph Convolutional Network)** | **GraphSAGE** | **GAT (Graph Attention Network)** |
| :------------------ | :------------------------------------------------------------------ | :------------------------------------------------------------------- | :--------------------------------------------------------------- |
| **핵심 아이디어** | 스펙트럼 이론을 근사한 **지역적 평균 집계** | **'집계 함수' 자체를 학습**하여 범용성 확보                          | 이웃별로 **'어텐션 가중치'를 학습**하여 중요도 선별                 |
| **학습 방식** | 직납적 (Transductive)                                               | **귀납적 (Inductive)**      | 귀납적 (Inductive)                                               |
| **이웃 가중치** | **동일** (차수로 정규화된 평균 가중치)                              | 집계 함수에 따라 다름 (Mean: 동일, Max: 승자독식)                    | **다름** (어텐션 스코어에 따라 동적으로 결정) |
| **확장성** | 낮음 (모든 이웃 사용)                                               | **매우 높음 (샘플링 사용)** | 높음 (샘플링과 병행 가능)                                        |
| **주요 장점** | 이론적 기반이 탄탄하고, 고정된 그래프 분석에 강력                     | **대규모 동적 그래프**에 적합, 실용성 및 확장성                      | 중요한 이웃을 선별하여 **모델 표현력 극대화** |

---

## 3. 핵심 용어 및 개념

-   **귀납적 학습**: 훈련 시 보지 못한 새로운 노드에 대해서도 임베딩을 생성할 수 있는 능력입니다. GraphSAGE와 GAT의 핵심 장점입니다.
-   **대칭 정규화 (`D̃⁻¹/² Ã D̃⁻¹/²`)**: GCN에서 사용하는 표준 정규화 방식으로, 정보를 주고받는 양쪽 노드의 차수를 모두 고려하여 학습을 안정시킵니다.
-   **어텐션 메커니즘**: GAT에서 사용하는 방식으로, 두 노드의 특징 벡터를 기반으로 '관계 점수'를 계산하고, 소프트맥스 함수를 통해 이를 '집중도 비율(가중치)'로 변환합니다. 이 과정은 데이터에 따라 가중치가 변하는 비선형 변환입니다.
-   **스펙트럼 그래프 이론**: 그래프를 라플라시안 행렬로 변환 후, 그 행렬의 스펙트럼(고유값, 고유벡터)을 분석해 그래프의 숨겨진 구조를 파악하는 학문입니다. 초기 GCN의 이론적 배경이 되었습니다.
-   **그래프 레벨 벡터**: 개별 노드 임베딩들을 풀링(Pooling)하여 그래프 전체를 대표하는 단 하나의 벡터로 요약한 것입니다. 그래프 분류 등의 Task에 사용됩니다.

---

## 4. 주요 질문 및 답변 (Key Q&A)

### GNN 기본 개념

-   **Q: `X ∈ ℝⁿˣᵈ` 와 같은 수식의 의미는?**
    -   A: `n`개의 노드가 각각 `d`개의 실수(Real Number) 값으로 이루어진 특징을 갖는 행렬이라는 의미입니다.
-   **Q: `h_i`와 `h_j`의 차이는?**
    -   A: `h_i`는 정보를 업데이트하려는 중심 노드의 임베딩, `h_j`는 그 중심 노드의 이웃 노드 `j`의 임베딩을 의미합니다.
-   **Q: 노드 자신의 임베딩은 어떻게 만들어지나?**
    -   A: 맨 처음(0 레이어)에는 초기 특징 벡터가 자신의 임베딩이 되며, 이후 각 레이어를 거치면서 '이전 레이어의 자신 정보 + 이전 레이어의 이웃 정보'가 종합되어 계속 새롭게 업데이트됩니다.

### GCN 관련 질문

-   **Q: '지역적 평균 연산'에서 '지역'이란?**
    -   A: 특정 노드와 그 노드에 직접 연결된 **1-hop 이웃까지의 범위**를 의미합니다.
-   **Q: `Ã`와 `~D`의 `~`(틸드)는 무슨 의미인가?**
    -   A: 원본 행렬을 **수정(modified)**했다는 의미입니다. `Ã`는 기존 인접 행렬 `A`에 셀프 루프(`+I`)를 추가한 것이고, `~D`는 그렇게 수정된 `Ã`로부터 계산된 새로운 차수 행렬입니다.
-   **Q: 왜 `~D`는 `Ã`의 행의 합으로 계산되나?**
    -   A: 그것이 바로 **'차수 행렬(Degree Matrix)'의 정의**이기 때문입니다. 한 노드의 차수(연결 수)는 인접 행렬에서 해당 노드를 나타내는 행의 합과 같습니다.

### GraphSAGE 관련 질문

-   **Q: 어떻게 GCN과 달리 '방법(함수)'을 학습하나?**
    -   A: 수많은 노드의 각기 다른 이웃 샘플들에서 공통적으로 잘 작동하는 **하나의 가중치 행렬 `W`**를 학습하기 때문입니다. 이 `W`가 바로 '이웃 정보를 변환하는 일반적인 규칙(함수)'이 됩니다.
-   **Q: '고정된 크기 이웃 샘플링'은 왜 확장성을 개선시키나?**
    -   A: 노드의 실제 이웃 수와 상관없이 항상 일정한 수의 이웃만 처리하므로, **계산량과 메모리 사용량이 예측 가능**해져 '이웃 폭발' 문제를 막을 수 있기 때문입니다.

### GAT 관련 질문

-   **Q: GAT의 어텐션 과정이 왜 비선형 변환인가?**
    -   A: 1) 어텐션 가중치(`α`)가 입력 데이터(`h_i`, `h_j`)에 따라 동적으로 변하고, 2) 가중치 계산 및 최종 결과에 LeakyReLU, Softmax 같은 비선형 함수가 사용되기 때문입니다.
