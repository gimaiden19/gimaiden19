# GNN에서 인접 행렬(A)에 단위 행렬(I)을 더하는 이유

그래프 신경망(GNN)을 공부하다 보면, 인접 행렬 `A`를 그대로 사용하지 않고 단위 행렬 `I`를 더한 `A' = A + I` (혹은 정규화된 형태)를 사용하는 코드를 자주 접하게 됩니다. 이 문서에서는 해당 연산의 의미와 원리, 그리고 필요성에 대해 설명합니다.

## 📜 핵심 요약 (TL;DR)

`A`에 `I`를 더하는 연산은 GNN의 정보 전달(Message Passing) 과정에서 **이웃 노드의 정보뿐만 아니라, 노드 자기 자신의 정보도 함께 고려하여 특징을 업데이트**하기 위함입니다.

이를 통해 GNN 레이어를 통과할 때 발생하는 **자기 정보 손실(Self-information Loss) 문제를 방지**하고 모델의 표현력을 높일 수 있습니다.

---

## 1. 무엇이 변하는가? (The "What")

- **인접 행렬 (Adjacency Matrix, A)**: 그래프의 노드 간 연결 관계를 나타냅니다. `A(i, j) = 1`은 노드 `i`와 `j`가 연결되었음을 의미합니다. 일반적으로 Self-loop가 없는 그래프의 대각 성분 `A(i, i)`는 0입니다.

- **단위 행렬 (Identity Matrix, I)**: 주 대각 성분만 1인 행렬입니다.

- **A + I**: 인접 행렬의 주 대각 성분을 모두 1로 만듭니다. 이는 그래프 관점에서 **모든 노드에 자기 자신으로 향하는 연결(Self-loop)을 추가**하는 것과 같습니다.

  $$A = \begin{pmatrix} 0 & 1 & 1 \\ 1 & 0 & 0 \\ 1 & 0 & 0 \end{pmatrix} \quad \xrightarrow{+I} \quad \tilde{A} = A+I = \begin{pmatrix} \mathbf{1} & 1 & 1 \\ 1 & \mathbf{1} & 0 \\ 1 & 0 & \mathbf{1} \end{pmatrix}$$

---

## 2. 왜 필요한가? (The "Why")

가장 기본적인 GNN의 레이어 전파 규칙은 다음과 같습니다.

$$H^{(l+1)} = \sigma(A H^{(l)} W^{(l)})$$

- $H^{(l)}$: 레이어 $l$의 노드 특징(feature) 행렬

이 수식의 핵심은 `A`와 `H`의 곱셈, 즉 `AH`에 있습니다. 이 연산은 각 노드에 대해 연결된 이웃 노드들의 특징 벡터를 모두 더하는(summing up) 역할을 합니다.

하지만 `A`의 대각 성분이 0이므로, 새로운 특징 $H^{(l+1)}$을 만들 때 **이웃 노드의 정보만 취합할 뿐 정작 자기 자신의 이전 특징 $H^{(l)}$은 반영하지 못합니다.** 이는 심각한 정보 손실로 이어질 수 있습니다.

---

## 3. 어떤 원리로 동작하는가? (The "How")

`A` 대신 `A+I`를 사용하면 이 문제를 해결할 수 있습니다.

$$H^{(l+1)} = \sigma((A+I) H^{(l)} W^{(l)})$$

` (A+I)H ` 연산이 어떻게 자기 자신의 정보를 포함시키는지 간단한 예시로 살펴보겠습니다.

- **특징 행렬 H**
  $$H = \begin{pmatrix} H_1 \\ H_2 \\ H_3 \end{pmatrix} = \begin{pmatrix} \text{노드 1 특징} \\ \text{노드 2 특징} \\ \text{노드 3 특징} \end{pmatrix}$$

- **연산 비교**
  - `A H`의 첫 번째 행 (노드 1의 새 특징 계산) :
    `0*H_1 + 1*H_2 + 1*H_3 = H_2 + H_3`
    (자기 자신($H_1$)의 정보가 누락됨)

  - `(A+I) H`의 첫 번째 행 (노드 1의 새 특징 계산) :
    `1*H_1 + 1*H_2 + 1*H_3 = H_1 + H_2 + H_3`
    (대각 성분 `1`로 인해 자기 자신($H_1$)의 정보가 포함됨)

결론적으로, 행렬 곱셈의 원리에 따라 `A+I`의 `I`가 **정보 취합 대상에 자기 자신을 포함시키는 스위치 역할**을 하게 됩니다.

---

## 4. 심화 질문: "가상의 값을 더하는 것이 아닌가?"

> Q: 원래 그래프에서 `A(i, i) = 0`인 것이 사실인데, 여기에 인위적으로 `1`을 부여하는 것은 데이터를 왜곡하는 것이 아닌가?

A: 매우 중요한 포인트입니다. 여기서 우리는 **'그래프의 정적인 구조'**와 **'GNN의 동적인 정보 취합 규칙'**을 분리해서 이해해야 합니다.

- **`A`의 역할**: "누가 누구의 이웃인가?"라는 그래프의 **구조적 사실**을 나타냅니다. (Data)
- **`A+I`의 역할**: "새로운 특징을 만들 때 누구의 정보를 가져올 것인가?"라는 **알고리즘의 행동 지침**을 정의합니다. (Algorithm Logic)

즉, `A+I`는 그래프의 구조가 '원래 이렇다'라고 왜곡하는 것이 아니라, 더 나은 학습을 위해 **"정보를 이렇게 모아라!"** 라고 GNN에게 알려주는 레시피(recipe)인 셈입니다. 마치 스터디 그룹에서 다른 친구들의 필기뿐만 아니라 자기 자신의 필기까지 함께 복습하라고 규칙을 정해주는 것과 같습니다.
