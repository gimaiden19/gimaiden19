# Triplet Loss 기반 푸드 페어링 모델 설계 및 고도화 여정

## 1. 초기 탐색: Triplet Loss와 푸드 페어링의 만남

- **개념 학습:** 유사한 데이터는 가깝게, 다른 데이터는 멀게 만드는 손실 함수 **Triplet Loss**에 대해 학습.
- **핵심 요소:** 기준점(**Anchor**), 유사한 샘플(**Positive**), 다른 샘플(**Negative**), 그리고 둘 사이의 거리를 보장하는 **Margin($\alpha$)**으로 구성됨.
- **적용 아이디어:** 이 개념을 푸드 페어링에 적용. '소고기(Anchor)'와 '마늘(Positive)'은 가깝게, '소고기(Anchor)'와 '고등어(Negative)'는 멀게 만들 수 있다면, 음식의 '맛의 공간(Flavor Space)'을 벡터로 표현할 수 있을 것이라 판단함.

## 2. 데이터 준비: 현실 세계의 '맛'을 데이터로 변환하기

- **데이터 소스:**
  - **정형 데이터:** '만개의레시피' 레시피 데이터 (명시적인 긍정 관계 확보)
  - **비정형 데이터:** SNS(블로그, 인스타그램) 게시물 (실제 소비 패턴 및 요리 단위 페어링 확보)
- **전처리 과정:**
  1. **웹 크롤링:** Python의 `requests`, `BeautifulSoup`을 사용하여 레시피 데이터(요리명, 재료, 조리법) 수집.
  2. **재료 정제:** `re`(정규표현식)를 사용해 `'돼지고기 300g'` -> `'돼지고기'` 처럼 재료명만 추출.
  3. **제목 정제:** `KoNLPy` 자연어 처리 라이브러리를 활용, 형태소 분석을 통해 `'여름입맛살리는~파프리카오이냉채'` -> `'파프리카오이냉채'` 와 같이 핵심 요리명만 추출.

## 3. 핵심 전략 수립: '관계'를 어떻게 정의할 것인가? (고민의 심화)

### 3.1. 긍정적(Positive) 관계 정의

- **초기 정의:** 하나의 레시피에 함께 등장하는 모든 재료의 쌍은 **'긍정적 관계'**라고 가정.
- **구현:** `itertools.combinations`를 사용하여 각 레시피의 재료 리스트에서 모든 조합을 생성하고, `collections.Counter`로 빈도 계산.

### 3.2. 부정적(Negative) 관계 정의: 고민의 변화

> #### 🤔 첫 번째 고민: "함께 쓰이지 않으면 부정적인 관계인가?"
>
> - **초기 아이디어:** '소고기'와 함께 등장한 적 없는 재료(e.g., '광어')를 Negative로 삼자. (Random Negative Sampling)
> - **문제점 발견:** '소고기'와 '닭고기'는 함께 요리되지 않지만, 그렇다고 서로 어울리지 않는 '부정적' 관계는 아니다. **'무관한 관계'와 '부정적 관계'를 구분해야 한다.**

> #### 🤔 두 번째 고민: "어떻게 '진짜' 부정적 관계를 찾을까?"
>
> - **대안 탐색:**
>   1.  **화학 성분 분석:** 과학적이지만 데이터 확보가 너무 어렵다.
>   2.  **사용자 리뷰 분석:** 확실하지만 데이터 수집 및 감성 분석의 난이도가 높다.
>   3.  **Hard Negative Mining:** 모델이 '헷갈려 하는' 관계를 찾아 학습시키는 방법.
> - **전략 채택:** **Hard Negative Mining**이 보유한 데이터로 시도해볼 가장 현실적인 방안이라 판단.

> #### 🤔 세 번째 고민: "Hard Negative는 오히려 독이 될 수 있지 않을까?"
>
> - **문제점 발견:** 가장 어려운 Negative (`d(A,N) < d(A,P)`)만 학습시키면, 실제로는 괜찮은 조합(e.g., 소고기-버섯)을 부정적 관계로 잘못 학습하거나, 모델 학습이 불안정해질 수 있다.
> - **최종 전략:** **Semi-Hard Negative Mining**을 채택. 너무 어렵지도, 쉽지도 않은, `d(A,P) < d(A,N) < d(A,P) + margin` 조건을 만족하는 '적당히 어려운' Negative를 찾아 학습 안정성과 성능을 모두 확보하기로 결정.

## 4. 모델 고도화: 실용적인 추천을 위한 추가적인 고민들

> #### 🤔 네 번째 고민: "강력한 긍정 관계가 약해지면 어떡하지?"
>
> - **문제점 발견:** Semi-Hard Negative, 즉 '경계선'에 있는 애매한 관계만 학습시키다 보면, '돼지고기-김치'처럼 아주 명확한 긍정 관계를 유지하려는 학습 신호가 부족해져 관계성이 약화될 수 있다.
> - **해결책:** **하이브리드 데이터셋 구성.** Semi-Hard Triplet(심화반)과 함께, 가장 빈번하게 등장하는 **Easy Positive Triplet**(기본반)을 일정 비율 섞어 학습. 이를 통해 모델이 핵심 관계를 잊지 않도록 보강.

> #### 🤔 다섯 번째 고민: "'김치찌개-공기밥' vs '김치찌개-쌀'의 차이는?"
>
> - **문제점 발견:** 모델이 **'요리(Dish)'**와 **'재료(Ingredient)'**라는 개념의 종류(Entity Type)를 구분하지 못하면, '김치찌개'에 '쌀'을 추천하는 등 의미적으로 부적절한 페어링이 발생할 수 있다.
> - **해결책:**
>   1.  **접두사 활용 (채택):** 데이터 전처리 시 `dish:김치찌개`, `ingr:쌀` 처럼 접두사를 붙여 모델이 이들을 별개의 아이템으로 인식하게 만든다. 구현이 간단하고 효과가 확실하여 **1순위로 채택**.
>   2.  **멀티태스크 학습:** 모델이 Triplet 관계와 함께 아이템의 종류(요리/재료)를 분류하는 부가 임무를 동시에 학습하게 만든다. 이는 더 정교한 방법으로, 추후 모델 고도화 시 적용하기로 결정.

## 5. 최종 설계: Multi-Task Learning 기반의 푸드 페어링 모델

고민의 흐름을 거쳐, 최종적으로 다음과 같은 정교한 모델링 파이프라인을 설계함.

1.  **데이터셋:** **접두사**로 '요리'와 '재료'가 구분되고, **타입 라벨**이 추가된 **하이브리드 Triplet 데이터셋**을 사용.
2.  **모델 아키텍처:** **Multi-Task Food Encoder**를 구축.
    - **임무 1:** Triplet 관계 학습을 위한 임베딩 벡터 출력.
    - **임무 2:** 아이템 타입 분류를 위한 클래스 예측 결과 출력.
3.  **학습:** **Triplet Loss**와 **분류 Loss(CrossEntropyLoss)**를 가중합하여, 페어링 관계와 아이템의 의미론적 종류를 동시에 학습.
4.  **활용:** 학습 완료 후, 모델의 **임베딩 벡터 출력**만을 사용하여 재료/요리 간의 코사인 유사도를 계산하고, 가장 유사도가 높은 아이템을 추천.

---
